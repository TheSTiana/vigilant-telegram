<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="twitter:card" content="summary_large_image" /><!-- Begin Jekyll SEO tag v2.8.0 -->
<title>NLP | Dat255 - Deep learning engineering</title>
<meta name="generator" content="Jekyll v4.1.1" />
<meta property="og:title" content="NLP" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="V2022" />
<meta property="og:description" content="V2022" />
<link rel="canonical" href="https://thestiana.github.io/vigilant-telegram/markdown/2020/01/05/Blog.html" />
<meta property="og:url" content="https://thestiana.github.io/vigilant-telegram/markdown/2020/01/05/Blog.html" />
<meta property="og:site_name" content="Dat255 - Deep learning engineering" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2020-01-05T00:00:00-06:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="NLP" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2020-01-05T00:00:00-06:00","datePublished":"2020-01-05T00:00:00-06:00","description":"V2022","headline":"NLP","mainEntityOfPage":{"@type":"WebPage","@id":"https://thestiana.github.io/vigilant-telegram/markdown/2020/01/05/Blog.html"},"url":"https://thestiana.github.io/vigilant-telegram/markdown/2020/01/05/Blog.html"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/vigilant-telegram/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://thestiana.github.io/vigilant-telegram/feed.xml" title="Dat255 - Deep learning engineering" /><link rel="shortcut icon" type="image/x-icon" href="/vigilant-telegram/images/favicon.ico"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/Primer/15.2.0/primer.css" integrity="sha512-xTz2ys4coGAOz8vuV1NcQBkgVmKhsSEtjbqyMJbBHRplFuvKIUo6xhLHpAyPt9mfR6twHJgn9OgVLuqOvjeBhg==" crossorigin="anonymous" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css" integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous" />

<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title") && (el.className != "emoji")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head>
<body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/vigilant-telegram/">Dat255 - Deep learning engineering</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/vigilant-telegram/about/">About Me</a><a class="page-link" href="/vigilant-telegram/search/">Search</a><a class="page-link" href="/vigilant-telegram/categories/">Tags</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">NLP</h1><p class="page-description">V2022</p><p class="post-meta post-meta-title"><time class="dt-published" datetime="2020-01-05T00:00:00-06:00" itemprop="datePublished">
        Jan 5, 2020
      </time>
       â€¢ <span class="read-time" title="Estimated read time">
    
    
      2 min read
    
</span></p>

    
      <p class="category-tags"><i class="fas fa-tags category-tags-icon"></i></i> 
      
        <a class="category-tags-link" href="/vigilant-telegram/categories/#markdown">markdown</a>
        
      
      </p>
    

    </header>

  <div class="post-content e-content" itemprop="articleBody">
    <h1 id="natural-language-processing">Natural language processing</h1>
<p>Natural Language Processing (NLP) is a subfield of linguistics and computer science and is used to give computers the ability to interpret and manipulate human language.
There are many applications of NLP some of which are content categorization, translation, text generation, and sentiment analysis.
While the field has existed for several decades, it is still fast-evolving, and breakthroughs still happen every year.</p>

<h3 id="universal-language-model-fine-tuning---ulmfit">Universal Language Model Fine-tuning - ULMFit</h3>
<p>When Jeremy Howard of FastAi published the paper <a href="https://arxiv.org/abs/1801.06146">Universal Language Model Fine-tuning for Text Classification</a> in 2018,
this was probably how far the field had gotten.
The idea proposed was a process of three stages of transfer learning.
Using a general purpose language model as the pretrained model which is then fine-tuned on a target corpus, and lastly transfer learning it to a classification task which is also fine-tuned on target corpus.
Language model has the objective of predicting the next word in a sentence,
and being capable of handling both grammar and semantics.
The process of training such a model is so called self-supervised learning.
General language model are trained on a large corpus, in this case Wikipedia.
The result is a pretrained model, which in this case is based on a AWD-LSTM architecture.
However, different domains have different language styles.
Text messages are mostly quite short and informal,
research papers on the other hand are long and formal.
Therefore, fine-tuning a pretrained language model on some target data should make it better at predicting the language style of its domain.</p>

<h3 id="transformers">Transformers</h3>
<p>In later years transformers have become the ruling architecture for creating NLP models.
RNN and LSTM which are the underlaying architecture of the language models in the ULMFit approach,
relies on handling the data in sequence. Which means word for word (or more likely token for token).
Which results in a rather slowed down training process.
This is one of the things transformers are able to address.
The transformer architecture allows the data pass in parallel, and train on whole sentences, which can greatly speed up the process.
There are today many different models which builds upon the transformer architecture.
One source for such models are the <a href="https://huggingface.co">Hugging Face</a> library.</p>

  </div><a class="u-url" href="/vigilant-telegram/markdown/2020/01/05/Blog.html" hidden></a>
</article>

      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/vigilant-telegram/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="/vigilant-telegram/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/vigilant-telegram/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
      <div class="footer-col">
        <p>Semester Project V22</p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"></ul>
</div>

  </div>

</footer>
</body>

</html>
